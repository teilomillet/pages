{
  
    
        "post0": {
            "title": "Introduction au Deep Learning",
            "content": "from fastbook import * from fastai import * . . Remerciement . Je tiens tout d&#39;abord à remercier OpenClassrooms pour m&#39;avoir fait confiance et permis d&#39;apprendre la Data Analyse pendant près d&#39;un an. De m&#39;avoir fourni les outils et la connaissance afin que je me develloppe. . En second lieu, Monsieur Christian Noumsi, qui a été mon mentor durant cette période. Sans ces précieux conseils et suggestion, je n&#39;aurais probablement pas appris autant que je l&#39;ai fait durant cette période. Son soutien et sa compréhension, m&#39;auront été d&#39;une grande aide tout au long de mon parcours. . Je dédis ce rapport à ma compagne qui aura été ma premiere supportrice et conseillère. Je la remercie pour le temps qu&#39;elle m&#39;a accordé afin que je m&#39;entraine durant mes présentations. J&#39;espere qu&#39;elle apprendra autant que j&#39;ai pu le faire avec ce rapport. . Introduction . Beaucoup de personnes ont entendu parler du Deep Learning, Machine Learning ou Réseau de Neurones. Mais peu savent ce que cela veut réellement dire. Qu&#39;elle est la différence entre ces termes, sont ils connectés ou bien sont il totalement différents? . Avec ce rapport, je vais essayer de démystifier les termes et de les expliquer. Nous allons tout d&#39;abord, parler de l&#39;histoire derièrre ces termes, leur signification et l&#39;evolution que la thématique à connu au cours des années. Nous décortiquerons comment marche un modèle de Deep Learning et les diffférentes étapes qui le compose. . Dans la deuxième partie, nous verrons comment la machine peu apprendre et s&#39;améliorer. Nous utiliserons un exemple concret pour expliquer la Descente de Gradient et l&#39;ajustement d&#39;un modèle. . Pour finir, nous verrons les termes qui entoure le machine learning et nous les définirons. . Le but de ce rapport est de vérifier ma connaissance et compréhension dans la matière avant de continuer dans le domaine. . Les fondamentaux . Dans cette partie, nous allons voir les origines du Réseau de Neurones, du Deep Learning et du Machine Learning. Nous allons explorer les différences entre ces dernières et comprendre ce qui les caractérisent. En fin, nous allons découvrir comment ils marchent ainsi que les termes associés aux différentes étapes. A la fin de cette première partie, ce trouve un récapitulatif de ce qu&#39;on aura vu dans cette partie, on y determinera aussi les limites du Deep Learning et les erreurs a ne pas commettre. . Origine du Deep Learning . En 1943, dans &quot;The bulletin of mathematical biphysics&quot; sort le papier &quot;A logical calculus of ideas immanent in nervous activity&quot;, écrit par Warren McCulloch et Walter Pitts. Leur objectif est de développer un model mathématique de neuronne artificiel. . En 1957, Frank Rosenblatt, améliore ce model pour developper le Mark I Perceptron. Le but de sa création est une machine capable d&#39;apprendre. La machine fonctionne grâce à des cables interconnectés entre eux, on y entre des nombres ainsi qu&#39;un &#39;poids&#39; (weights) et un &#39;biais&#39; (bias). La machine ensuite multiplie les nombres saisies par leurs poids respectifs pour obtenir un résultat, ce résultat est additionné avec le biais pour obtenir un résultat final. . Perceptron: (saisie * poids) + biais = résultat final. . Par la suite, en 1969, les professeurs du MIT, Marvin Minsky et Seymour Papart démontre que le Mark I Perceptron ne parvient pas apprendre de simple fonction mathématique (XOR par exemple). Mais il montre aussi que le fait d&#39;ajouter des couches supplémentaire permet d&#39;améliorer ces résultats. Depuis, aucune nouveauté ou amélioration n&#39;a été éffectué. . Jusqu&#39;en 1986, à la sortie de &quot;Parallel Distributed Processing (PDP)&quot; par le MIT Press. Dans ce livre, il est question d&#39;un cadre de travail pour modéliser le processus cognitif. Par cela, il cherche à expliquer la raison pour laquelle l&#39;ordinateur n&#39;arrivent pas à obtenir les mêmes résultats que le cerveau humain, pour tache simple comme reconnaitre une image d&#39;un chien de celle d&#39;un chat. Le model PDP cherche à se rapprocher de la manière de penser du cerveau et par conséquent il est mieux adapter pour réaliser ce type de taches. . Cette approche reste étroitement liée à celle encore effectuée aujourd&#39;hui pour les réseaux de neuronnes. Le Parallel Distributed Processing est défini comme suit : . Un ensemble d&#39;unités à traiter | Un état d&#39;activation | Une fonction de résultat pour chaque unités | Un modèle de connectivité entre les unités | Une règle de propagation | Une règle d&#39;activation | Une règle d&#39;apprentissage | Un environnement dans lequel le système doit fonctionner | Dans les années 80 et 90, les modèles de reseaux neuronnaux sont utilisés pour des cas pratiques. A cette époque, des chercheurs commencent à ajouter des couches (4. le modèle de connectivité entre les unités) au réseaux de neuronnes pour finalement obtenir le Deep Learning. Ainsi, le Deep Learning est un réseau de neuronnes qui comprend plus de 2 couches. . Aujourd&#39;hui, comme Rosenblatt le décrivait nous avons accès «à des machines capable de percevoir, reconnaitre et identifier son environnement sans l&#39;aide de l&#39;humain ou de son control.» . Le Machine Learning . Le Machine Learning, comme un programme informatique, à pour but de réaliser une tâche. . De manière générale, un programme obéit à un certain nombre d&#39;étapes. Ces étapes ont pour but d&#39;arriver à un résultat final. Visuellement, voila à quoi cela pourrait ressembler: . gv(&#39;&#39;&#39;programme[shape=box3d width=1 height=0.7] entrées-&gt;programme-&gt;resultats&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G programme programme resultats resultats programme&#45;&gt;resultats entrées entrées entrées&#45;&gt;programme En 1949, un chercheur de chez IBM, Arthur Samuel travail sur un programme qui permettrait par exemple aux ordinateurs de différencier les images de chats et de chiens. Ce fut la naissance du Machine Learning. . Il immagine qu&#39;au lieu de coder une à une les étapes requisent pour résoudre un probleme, il suffirait de présenter des exemples de problèmes résolus et laisser le programme trouver comment résoudre le problème par lui-même. . En 1961, son programme de jeux de dames a battut le champion du Connecticut. Dans son essaie de 1962, &quot;Artificial Intelligence: A Frontier of Automation&quot;, il décrit comment il a fait: . «Supposons que nous disposions d&#39;un moyen automatique de tester l&#39;efficacité de toute attribution de poids actuelle en termes de performance réelle et que nous fournissions un mécanisme permettant de modifier l&#39;attribution de poids de manière à maximiser la performance. Il n&#39;est pas nécessaire d&#39;entrer dans les détails d&#39;une telle procédure pour constater qu&#39;elle pourrait être entièrement automatique et qu&#39;une machine ainsi programmée &quot;apprendrait&quot; de son expérience.» . Un modèle produit un résultat, non seulement grâce aux entrées mais avec l&#39;aide de poids, qui en fonction de leurs performance par rapport au résultat doivent etre ajuster de manière à maximiser la performance du modèle. . Voici une représentation visuelle: . gv(&#39;&#39;&#39;modèle[shape=box3d width=1 height=0.7] entrées-&gt;modèle-&gt;resultats; poids-&gt;modèle&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G modèle modèle resultats resultats modèle&#45;&gt;resultats entrées entrées entrées&#45;&gt;modèle poids poids poids&#45;&gt;modèle Une fois le procédé d&#39;ajustement des poids automatisé, la machine apprend (learn) de son expérience. Ainsi l&#39;homme ne serait plus derière la machine pour modifier l&#39;ajustement des poids mais celle-ci, le ferait automatiquement en se basant sur sa performance. . La performance du modèle est mesuré grâce . Durant sa phase d&#39;entrainement, le modèle fait des estimations qu&#39;il compare avec la finalité attendu. La différence entre l&#39;estimation du modèle et la finalité attendu, s&#39;appelle la performance. Ainsi le modèle ajuste ces poids en fonction de la performance précédemment obtenu, jusqu&#39;a obtenir les poids qui donneront la meilleur performance possible ou que nous arretions l&#39;entrainement du modèle. . Visuellle representant le procédé d&#39;entrainement d&#39;un modèle de Machine Learning: . gv(&#39;&#39;&#39;ordering=in modèle[shape=box3d width=1 height=0.7] entrées-&gt;modèle-&gt;estimations; poids-&gt;modèle; estimations-&gt;performance performance-&gt;poids[constraint=false label=ajustement]&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G modèle modèle estimations estimations modèle&#45;&gt;estimations entrées entrées entrées&#45;&gt;modèle performance performance estimations&#45;&gt;performance poids poids poids&#45;&gt;modèle performance&#45;&gt;poids ajustement Une fois l&#39;entrainement terminé, les poids font partie intégrante du modèle, ils ne pourront plus etre modifiés. Nous donnant ainsi le graphique de départ, on remarque que seulement le mot &quot;programme&quot; à été changé par &quot;modèle&quot;. Notre modèle agit donc mainteant comme un programme a part entière : . gv(&#39;&#39;&#39;modèle[shape=box3d width=1 height=0.7] entrées-&gt;modèle-&gt;resultats&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G modèle modèle resultats resultats modèle&#45;&gt;resultats entrées entrées entrées&#45;&gt;modèle Machine Learning : L&#39;entrainement de programmes qui ont été développés en permettant à un ordinateur d&#39;apprendre de son expérience, plutôt qu&#39;en codant manuellement les différentes étapes. . Conclusion de la Partie 1 . Pour la suite du rapport, nous utilisons d&#39;autres termes pour parler de certaines choses: . Les poids (et biais) sont appelés &quot;parametres&quot; | Les prédictions sont calculés depuis les variables indépendantes, cad les données (sans inclure les labels) | Les données que le modèle essaient de prédire sont appelés les labels | Les resultats du modèle sont appelés &quot;prédictions&quot; | La mesure de la performance que le modèle utilise durant son entrainement est appelé &quot;perte&quot; La perte depend de la prédiction mais aussi de la variable dépendante (labels) | . | . Voici le visuel final, d&#39;un modèle de Deep Learning : . gv(&#39;&#39;&#39;ordering=in modèle[shape=box3d width=1 height=0.7 label=modèle] entrées-&gt;modèle-&gt;predictions; parametres-&gt;modèle; labels-&gt;pertes; predictions-&gt;pertes pertes-&gt;parametres[constraint=false label=ajustement]&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G modèle modèle predictions predictions modèle&#45;&gt;predictions entrées entrées entrées&#45;&gt;modèle pertes pertes predictions&#45;&gt;pertes parametres parametres parametres&#45;&gt;modèle labels labels labels&#45;&gt;pertes pertes&#45;&gt;parametres ajustement En revanche, notre modèle est limité par: . Les données Leurs étendues et leurs variétés | On ne peut pas entrainer de modèle sans celles-ci | . | Le modèle à besoin de données labelisées pour s&#39;entrainer et mesurer sa performance | . Mais il faut faire attention: . Aux rétroactions (feedback loop). | Aux surapprentissage, le model peut apprendre spécifiquement le jeu de données et in fine n&#39;etre bon que sur ce jeu de données. | Aux données d&#39;entrées, qu&#39;elles ne soient pas extremement biaisais des le début par exemple. | Aux changements d&#39;environnement, entre l&#39;entrainement du modèle et son utilisation. | . Pour recapituler, un réseau de neurones est une sorte de modèle de Machine Learning et le deep learning est un réseau de neurones avec des couches suplémentaire (&gt;2). . Stochastic Gradient Descent (SGD) . Maintenant on sait à quoi servent les poids, on sait comment fonctionne le Machine Learning et on sait que les poids sont ajuster en fonction de la performance. Mais comment sont réellement ajusté les poids ? . Pour trouver les valeurs à attribuer aux poids et ce de façon automatique, nous allons utiliser la Descente de Gradient Stochastique (SGD). . La Descente de Gradient Stochastique, donne un poids à chaque unités d&#39;entrées, de façon à ce que les unités d&#39;entrées qui sont le plus probable d&#39;avoir un impact positif sur notre résultat est un plus grand poids que celles avec une faible probabilité. . La probabilité que la prediction soit positive = la somme des unités multiplié par leurs poids respective. . Nous cherchons les valeurs des poids qui nous permettront d&#39;obtenir le meilleur résultat. Il nous manque donc la manière de les améliorer. Afin de se faire nous allons réaliser quelques étapes: . Initialisation des poids de façon aléatoire | Prediction: pour chaque unités, utiliser le poids assigné pour prédire le résultat | Perte: d&#39;après ces prédictions, calculer sa performance | Gradient: comment la modification des poids impact notre performance (perte) | Ajustement des poids: en se basant sur le gradient | Repetition: retour à l&#39;étape 2. et renouvelement du processus | Stop: arret du processus d&#39;entrainement du modèle | gv(&#39;&#39;&#39; init-&gt;prediction-&gt;perte-&gt;gradient-&gt;ajustement-&gt;stop ajustement-&gt;prediction[label=repetition] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G init init prediction prediction init&#45;&gt;prediction perte perte prediction&#45;&gt;perte gradient gradient perte&#45;&gt;gradient ajustement ajustement gradient&#45;&gt;ajustement ajustement&#45;&gt;prediction repetition stop stop ajustement&#45;&gt;stop Le gradient . L&#39;objectif du Gradient est d&#39;optimiser notre perte en modifiant les poids attribué aux parametres. Ce qui se passe durant 5. l&#39;ajustement. Pour ce faire le Gradient calcul la dérivée. . La dérivée calcul le changement plutot que la valeur. Elle nous indique à quelle vitesse (%) un changement a lieu entre les valeurs sous-jacente. Plus spécifiquement elle est égale à : . Le changement de valeur dans la fonction / par le changement de valeur dans les parametres . Lorsque l&#39;on sait comment la valeur va changer, nous savons comment l&#39;optimiser. Une fonction à plusieurs poids (pour chaque entrées) qui doivent etre ajuster, ce qui résulte en autant de gradient qu&#39;il y a de poids. Pour ce faire, le gradient calcul la dérivé d&#39;un poids et traite toute les autres comme des constantes, et ce pour chaque poids. . Ici réside la clef de l&#39;optimisation d&#39;un modèle de Machine Learning. . Taux d&#39;apprentissage . Le taux d&#39;apprentissage permet de décidé comment les parametres (poids) vont changer par rapport au gradient. C&#39;est à dire que l&#39;on va muliplié le taux d&#39;apprentissage par le gradient pour obtenir notre ajustement. Comme nous souhaitons minimiser notre perte, nous allons soustraire ce calcul au parametres pour les optimiser. Ceci nous permet d&#39;ajuster les parametres dans la direction du zéro. Ainsi augmentant les parametres lorsque la direction est négative et les baissant lorsque la direction est positive. Le but est d&#39;atteindre une perte la plus proche de zéro. . poids -= gradient(poids) * taux d&#39;apprentissage . Cela s&#39;appelle l&#39;étape d&#39;optimisation. Le choix du taux d&#39;apprentissage, aura un grand impact sur cette étape. Un faible taux d&#39;apprentissage, rendra le modèle lent dans son apprentissage alors qu&#39;un taux d&#39;apprentissage trop élevé peut résulté en une performance qui regresse ou divergente. . Exemple d&#39;un mod&#232;le &#224; l&#39;aide de la Descente de Gradient . Nous allons créer un gradient pour trouver la valeur minimal. . Dans cette exemple, nous mesurons la vitesse des voitures qui circulent sur le périphérique parisien chaque heure d&#39;une journée. . temps = torch.arange(0,25).float() temps . tensor([ 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.]) . vitesse = torch.randn(25)*3 + 0.85*(temps-11)**2 + 1 plt.scatter(temps, vitesse); . Voici le rendu, il semble y avoir des bouchons entre 10h et 15h, et que le traffic devient plus fluide après 20h. Il n&#39;est pas facile de déterminer a quelle vitesse roulait une voiture à une heure précise. En utilisant la Descente de Gradient, on peu estimer à l&#39;aide de la fonction quadratique: a (temps** 2)+ (b temps) +c. . Nous cherchons à distinguer entre: les entrées (le l&#39;heure (temps) à laquelle nous mesurons la vitesse des voitures) et ces parametres (la valeur qui défini quelle quadratique nous essayons). Pour ce faire nous collectons les parametres dans un unique argument afin de séparé le temps (t) et les parametres (params). . def fonction(t, params): a,b,c = params return a*(t**2) + (b*t) + c . En d&#39;autre mots, nous avons restreint le probleme, à la recherche de la meilleur fonction quadratique (a,b,c). Nous devons donc simplement trouver quels sont les meilleurs valeurs pour a, b et c. . Le procédé est le même pour les autres cas, nous cherchons la valeurs des parametres. A cette fin, nous utilison la fonction de &#39;perte&#39; qui nous retournera une valeur basé sur la différence entre la prédiction et la cible (ici la vitesse), où une faible &#39;perte&#39; nous donnera une &quot;meilleur&quot; performance. . Dans ce cas, la fonction de &#39;perte&#39; est l&#39;erreur quadratic moyenne (mean squared error) car il s&#39;agit de données continues (numérique) . def mse(predictions, cibles): return ((predictions-cibles)**2).mean() . 1. Initialisation des parametres (poids) . On initialize les poids avec des valeurs aléatoire et indiquons a PyTorch que nous souhaitons retenir leurs gradients . params = torch.randn(3).requires_grad_() . Pr&#233;dictions . Nous calculons les prédictions du modèle en utilisant la fonction précèdemment codé. . predictions = fonction(temps, params) . Maintenant visualisons, comment notre modèle performe avec des parametres aléatoire. . def show(prediction, ax=None): if ax is None: ax=plt.subplots()[1] ax.scatter(temps, vitesse) ax.scatter(temps, to_np(predictions), color=&#39;red&#39;) ax.set_ylim(-100, 250) . show(predictions) . En bleu, sont les données cibles et en rouge les données de la prédiction. On voit clairement que le parametres ne sont pas en accord avec la cible et qu&#39;il nous propose même des valeurs de vitesse négative. . Perte . Nous allons mesurer la performance de notre modèle, à l&#39;aide de la fonction mean squared error, précèdemment créer pour. . perte = mse(predictions, vitesse) perte . tensor(59678.8281, grad_fn=&lt;MeanBackward0&gt;) . Notre objectif est maintenant d&#39;améliorer ce résultat, en essayant de le diminuer au maximum. Pour cela nous allons utiliser le gradient. . Gradient . Dans cette étape nous allons calculer le gradient, soit approximativement le changement nécessaire au parametres afin qu&#39;il s&#39;améliore. . perte.backward() params.grad . tensor([128103.9688, 6573.3862, 333.9178]) . .backward() signifie &quot;Back propagation&quot;. Il s&#39;agit du processus de calcul de la dérivéee. . .grad signifie gradient. Cela nous permet d&#39;obtenir le gradient (dérivée). . Ajustement . Maintenant que l&#39;on connait le gradient. Nous devons le multiplié par un taux d&#39;apprentissage afin que la machine apprenne. Dans ce cas, on choisi arbitrairement un taux d&#39;apprentissage de 0.0001. . ta = 1e-5 params.data -= ta * params.grad.data params.grad = None . .data nous permet de ne pas calculer les gradients durant l&#39;ajustement, car on souhaite que les gradients soit calculer seulement lors de la prédiction. . Retour &#224; l&#39;&#233;tape de pr&#233;diction . Retour à l&#39;étape 2. Prédiction, ici nous allons comparer notre résultat obtenu précedemment avec celui obtenu après avoir effectué l&#39;ajustement. . predictions = fonction(temps, params) perte = mse(predictions, vitesse) perte . tensor(11477.2236, grad_fn=&lt;MeanBackward0&gt;) . On remarque la perte à baisser et c&#39;est ce que nous cherchions à faire! Notre modèle c&#39;est belle et bien amélioré. . show(predictions) . On peut aussi visualiser l&#39;amélioration de notre modèle. . Ainsi, nous pouvons créer une fonction qui permettra d&#39;effectuer toute ces étapes. . def ajustement(params, prn=True): predictions = fonction(temps, params) perte = mse(predictions, vitesse) perte.backward() params.data -= ta * params.grad.data params.grad = None if prn: print(perte.item()) return predictions . Faisons le plusieurs fois, pour voir si notre modèle s&#39;améliore. Lorsque l&#39;on défini combien d&#39;ajustement le modèle va effectuer avant de s&#39;arreter, cela s&#39;appelle une epoch. Dans le cas suivant, il y a 5 epochs. . for i in range(6): ajustement(params) . 11477.2236328125 3211.542724609375 1794.1199951171875 1551.0457763671875 1509.349853515625 1502.18701171875 . Pour r&#233;sumer . Les poids de notre modèle peuvent etre choisi de façon aléatoire ou bien venir d&#39;un modèle pré-entrainé (transfert learning). Le modèle devra alors apprendre pour trouver de meilleur poids. . A cette fin, on compare les prédictions du modèle avec les cibles (labels) à l&#39;aide de la fonction &#39;perte&#39;. Cette perte doit etre le plus proche de zéro possible. . Nos poids doivent etre amélioré, on le fait en fournissant au modèle des données. Après avoir passer les étapes du modèle, on obtient une &#39;perte&#39;, cette perte nous indique &quot;de combien le modèle à faux&quot; puis on change les poids pour obtenir un meilleur résultat. . Pour trouver comment changer les poids, on utilise le gradient (la dériviée), celui-ci est multiplié par un taux d&#39;apprentissage (ampleur de l&#39;apprentissage) qui nous donne alors la direction et l&#39;amplitude de l&#39;ajustement des poids. . Les sp&#233;cificit&#233;s . Utilisation du Deep Learning . Le Deep Learning peut etre utiliser pour remplir différentes tâches: . Vision : Detection et Classification d&#39;images | Texte : Classification (analyse du sentiment), Génération de texte et Traduction | Tableau : Classification (Travail avec beaucoup de données numérique) | &quot;Recommendation&quot; : Prédiction du prochain achat par ex. (différent de proposition | Multi-modal : Mix des precedentes catégories | Autres : Il existe de nombreuse possibilités en utilisant le Deep Learning pour completé une tâche. | . Classification et Regression . Les deux types de modèle principaux sont la classification et la regression. . Le modèle de classification prédit une catégorie (ex, un chat ou un chien). . Différent d&#39;une Regression Linéaire, le modèle de Regression prédit une ou plusieurs valeurs numérique (ex, une température) . Le mod&#232;le basic . Parfois un simple modèle basic, facile à construire, est plus performant qu&#39;un modèle de Deep Learning. De plus ce modèle basic, permet de comparer les résultats du modèle de Deep Learning avec un autre modèle. Avant de commencer, il faut construire ce modèle basic afin d&#39;essayer de trouver une solution qui soit claire et qui fournisse un résultat proche de celui espéré avec le Machine Learning. . Le modèle basic doit etre simple, il peut être constituer en quelques calculs mathématiques, en revanche le modèle basic ce veut plus performant qu&#39;un modèle qui résulte de façon aléatoire. Et bien évidemment, ce n&#39;est pas un modèle utilisant le Machine Learning. . Souvent un modèle basic, va être la représentation de notre propre réflection à la question: Comment prédire efficacement le résultat ? . Ex: Prédire le prix d&#39;un certain produit ? On calcul le prix moyen des produits de la même catégorie . La validation du mod&#232;le (metric) . Maintenant que nous savons comment entrainer un modèle, comment savoir si celui-ci est réellement performant? . Pour cela, il faut utiliser un set de validation. Ce sont des données qui ont été mis à l&#39;écart explicitement afin de comparer les prédictions de notre modèle avec la réalité. Ainsi on obtient, une mesure précise de la performance. . Mais quelle est la différence entre la perte et la metric ? . La différence réside dans le fait que la metric aide l&#39;humain à comprendre la performance du modèle alors que la perte aide la machine à apprendre de ces erreurs. . La metric est la valeur dont nous nous soucions réellement, c&#39;est la mesure qui nous indique comment le modèle performe réellement. . La perte doit être choisi de sorte à avoir une dérivée qui réagi a l&#39;ajustement des parametres. . la metric va comparer . La mesure de la performance du modèle comparant la prédiction avec un jeu de données &quot;valide&quot; s&#39;appele la &quot;metric&quot; (in fine c&#39;est la mesure en laquelle l&#39;homme juge la performance du modèle) | Le jeu de données valide (validation set) est un jeu de données mis à l&#39;écart lors de l&#39;entrainement, il permet de vérifier la performance du modèle (metric) et ne contient aucune données utilisé lors de l&#39;entrainement. | . Le transfert learning . Le transfert learning, nous permet d&#39;utiliser un modèle qui a déja été entrainé (sur d&#39;autres données proche des notres). Le modèle possèdent alors des parametres prochent de ceux que nous souhaitons obtenir pour notre prédiction. . Nous pouvons alors rapidement ré-entrainer ce modèle sur nos données pour obtenir un &quot;meilleur&quot; résultat qu&#39;un nouveau modèle. Ce n&#39;est pas nécessairement le cas (bien que souvent), mais cette aspect à la faculté d&#39;etre bien plus rapide. Cette technique permet d&#39;entrainé un modèle lorsque l&#39;on à peu de données ou bien peu de capacité de calcul (pour l&#39;entrainement du modèle). . Au lieu d&#39;utiliser des parametres choisi de façon aléatoire, les paramatres du modèle pré-entrainé sont proches de ceux que nous souhaitons obtenir. . Conclusion . Dans ce rapport, nous avons vu l&#39;histoire du Machine Learning, du Deep Learning et des Reseau de Neurones. Nous avons appris à les différencier et compris comment ils étaient relié. Nous savons comment la machine est capable d&#39;apprendre et de s&#39;améliorer. Ce rapport constitue les fondations pour aller de l&#39;avant et commencer à pousser l&#39;apprentissage plus loin. .",
            "url": "https://teilomillet.github.io/pages/2022/05/27/P8-Rapport.html",
            "relUrl": "/2022/05/27/P8-Rapport.html",
            "date": " • May 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Introduction au Deep Learning",
            "content": "from fastbook import * from fastai import * . . Remerciement . Je tiens tout d&#39;abord à remercier OpenClassrooms pour m&#39;avoir fait confiance et permis d&#39;apprendre la Data Analyse pendant près d&#39;un an. De m&#39;avoir fourni les outils et la connaissance afin que je me develloppe. . En second lieu, Monsieur Christian Noumsi, qui a été mon mentor durant cette période. Sans ces précieux conseils et suggestion, je n&#39;aurais probablement pas appris autant que je l&#39;ai fait durant cette période. Son soutien et sa compréhension, m&#39;auront été d&#39;une grande aide tout au long de mon parcours. . Je dédis ce rapport à ma compagne qui aura été ma premiere supportrice et conseillère. Je la remercie pour le temps qu&#39;elle m&#39;a accordé afin que je m&#39;entraine durant mes présentations. J&#39;espere qu&#39;elle apprendra autant que j&#39;ai pu le faire avec ce rapport. . Introduction . Beaucoup de personnes ont entendu parler du Deep Learning, Machine Learning ou Réseau de Neurones. Mais peu savent ce que cela veut réellement dire. Qu&#39;elle est la différence entre ces termes, sont ils connectés ou bien sont il totalement différents? . Avec ce rapport, je vais essayer de démystifier les termes et de les expliquer. Nous allons tout d&#39;abord, parler de l&#39;histoire derièrre ces termes, leur signification et l&#39;evolution que la thématique à connu au cours des années. Nous décortiquerons comment marche un modèle de Deep Learning et les diffférentes étapes qui le compose. . Dans la deuxième partie, nous verrons comment la machine peu apprendre et s&#39;améliorer. Nous utiliserons un exemple concret pour expliquer la Descente de Gradient et l&#39;ajustement d&#39;un modèle. . Pour finir, nous verrons les termes qui entoure le machine learning et nous les définirons. . Le but de ce rapport est de vérifier ma connaissance et compréhension dans la matière avant de continuer dans le domaine. . Les fondamentaux . Dans cette partie, nous allons voir les origines du Réseau de Neurones, du Deep Learning et du Machine Learning. Nous allons explorer les différences entre ces dernières et comprendre ce qui les caractérisent. En fin, nous allons découvrir comment ils marchent ainsi que les termes associés aux différentes étapes. A la fin de cette première partie, ce trouve un récapitulatif de ce qu&#39;on aura vu dans cette partie, on y determinera aussi les limites du Deep Learning et les erreurs a ne pas commettre. . Origine du Deep Learning . En 1943, dans &quot;The bulletin of mathematical biphysics&quot; sort le papier &quot;A logical calculus of ideas immanent in nervous activity&quot;, écrit par Warren McCulloch et Walter Pitts. Leur objectif est de développer un model mathématique de neuronne artificiel. . En 1957, Frank Rosenblatt, améliore ce model pour developper le Mark I Perceptron. Le but de sa création est une machine capable d&#39;apprendre. La machine fonctionne grâce à des cables interconnectés entre eux, on y entre des nombres ainsi qu&#39;un &#39;poids&#39; (weights) et un &#39;biais&#39; (bias). La machine ensuite multiplie les nombres saisies par leurs poids respectifs pour obtenir un résultat, ce résultat est additionné avec le biais pour obtenir un résultat final. . Perceptron: (saisie * poids) + biais = résultat final. . Par la suite, en 1969, les professeurs du MIT, Marvin Minsky et Seymour Papart démontre que le Mark I Perceptron ne parvient pas apprendre de simple fonction mathématique (XOR par exemple). Mais il montre aussi que le fait d&#39;ajouter des couches supplémentaire permet d&#39;améliorer ces résultats. Depuis, aucune nouveauté ou amélioration n&#39;a été éffectué. . Jusqu&#39;en 1986, à la sortie de &quot;Parallel Distributed Processing (PDP)&quot; par le MIT Press. Dans ce livre, il est question d&#39;un cadre de travail pour modéliser le processus cognitif. Par cela, il cherche à expliquer la raison pour laquelle l&#39;ordinateur n&#39;arrivent pas à obtenir les mêmes résultats que le cerveau humain, pour tache simple comme reconnaitre une image d&#39;un chien de celle d&#39;un chat. Le model PDP cherche à se rapprocher de la manière de penser du cerveau et par conséquent il est mieux adapter pour réaliser ce type de taches. . Cette approche reste étroitement liée à celle encore effectuée aujourd&#39;hui pour les réseaux de neuronnes. Le Parallel Distributed Processing est défini comme suit : . Un ensemble d&#39;unités à traiter | Un état d&#39;activation | Une fonction de résultat pour chaque unités | Un modèle de connectivité entre les unités | Une règle de propagation | Une règle d&#39;activation | Une règle d&#39;apprentissage | Un environnement dans lequel le système doit fonctionner | Dans les années 80 et 90, les modèles de reseaux neuronnaux sont utilisés pour des cas pratiques. A cette époque, des chercheurs commencent à ajouter des couches (4. le modèle de connectivité entre les unités) au réseaux de neuronnes pour finalement obtenir le Deep Learning. Ainsi, le Deep Learning est un réseau de neuronnes qui comprend plus de 2 couches. . Aujourd&#39;hui, comme Rosenblatt le décrivait nous avons accès «à des machines capable de percevoir, reconnaitre et identifier son environnement sans l&#39;aide de l&#39;humain ou de son control.» . Le Machine Learning . Le Machine Learning, comme un programme informatique, à pour but de réaliser une tâche. . De manière générale, un programme obéit à un certain nombre d&#39;étapes. Ces étapes ont pour but d&#39;arriver à un résultat final. Visuellement, voila à quoi cela pourrait ressembler: . gv(&#39;&#39;&#39;programme[shape=box3d width=1 height=0.7] entrées-&gt;programme-&gt;resultats&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G programme programme resultats resultats programme&#45;&gt;resultats entrées entrées entrées&#45;&gt;programme En 1949, un chercheur de chez IBM, Arthur Samuel travail sur un programme qui permettrait par exemple aux ordinateurs de différencier les images de chats et de chiens. Ce fut la naissance du Machine Learning. . Il immagine qu&#39;au lieu de coder une à une les étapes requisent pour résoudre un probleme, il suffirait de présenter des exemples de problèmes résolus et laisser le programme trouver comment résoudre le problème par lui-même. . En 1961, son programme de jeux de dames a battut le champion du Connecticut. Dans son essaie de 1962, &quot;Artificial Intelligence: A Frontier of Automation&quot;, il décrit comment il a fait: . «Supposons que nous disposions d&#39;un moyen automatique de tester l&#39;efficacité de toute attribution de poids actuelle en termes de performance réelle et que nous fournissions un mécanisme permettant de modifier l&#39;attribution de poids de manière à maximiser la performance. Il n&#39;est pas nécessaire d&#39;entrer dans les détails d&#39;une telle procédure pour constater qu&#39;elle pourrait être entièrement automatique et qu&#39;une machine ainsi programmée &quot;apprendrait&quot; de son expérience.» . Un modèle produit un résultat, non seulement grâce aux entrées mais avec l&#39;aide de poids, qui en fonction de leurs performance par rapport au résultat doivent etre ajuster de manière à maximiser la performance du modèle. . Voici une représentation visuelle: . gv(&#39;&#39;&#39;modèle[shape=box3d width=1 height=0.7] entrées-&gt;modèle-&gt;resultats; poids-&gt;modèle&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G modèle modèle resultats resultats modèle&#45;&gt;resultats entrées entrées entrées&#45;&gt;modèle poids poids poids&#45;&gt;modèle Une fois le procédé d&#39;ajustement des poids automatisé, la machine apprend (learn) de son expérience. Ainsi l&#39;homme ne serait plus derière la machine pour modifier l&#39;ajustement des poids mais celle-ci, le ferait automatiquement en se basant sur sa performance. . La performance du modèle est mesuré grâce . Durant sa phase d&#39;entrainement, le modèle fait des estimations qu&#39;il compare avec la finalité attendu. La différence entre l&#39;estimation du modèle et la finalité attendu, s&#39;appelle la performance. Ainsi le modèle ajuste ces poids en fonction de la performance précédemment obtenu, jusqu&#39;a obtenir les poids qui donneront la meilleur performance possible ou que nous arretions l&#39;entrainement du modèle. . Visuellle representant le procédé d&#39;entrainement d&#39;un modèle de Machine Learning: . gv(&#39;&#39;&#39;ordering=in modèle[shape=box3d width=1 height=0.7] entrées-&gt;modèle-&gt;estimations; poids-&gt;modèle; estimations-&gt;performance performance-&gt;poids[constraint=false label=ajustement]&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G modèle modèle estimations estimations modèle&#45;&gt;estimations entrées entrées entrées&#45;&gt;modèle performance performance estimations&#45;&gt;performance poids poids poids&#45;&gt;modèle performance&#45;&gt;poids ajustement Une fois l&#39;entrainement terminé, les poids font partie intégrante du modèle, ils ne pourront plus etre modifiés. Nous donnant ainsi le graphique de départ, on remarque que seulement le mot &quot;programme&quot; à été changé par &quot;modèle&quot;. Notre modèle agit donc mainteant comme un programme a part entière : . gv(&#39;&#39;&#39;modèle[shape=box3d width=1 height=0.7] entrées-&gt;modèle-&gt;resultats&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G modèle modèle resultats resultats modèle&#45;&gt;resultats entrées entrées entrées&#45;&gt;modèle Machine Learning : L&#39;entrainement de programmes qui ont été développés en permettant à un ordinateur d&#39;apprendre de son expérience, plutôt qu&#39;en codant manuellement les différentes étapes. . Conclusion de la Partie 1 . Pour la suite du rapport, nous utilisons d&#39;autres termes pour parler de certaines choses: . Les poids (et biais) sont appelés &quot;parametres&quot; | Les prédictions sont calculés depuis les variables indépendantes, cad les données (sans inclure les labels) | Les données que le modèle essaient de prédire sont appelés les labels | Les resultats du modèle sont appelés &quot;prédictions&quot; | La mesure de la performance que le modèle utilise durant son entrainement est appelé &quot;perte&quot; La perte depend de la prédiction mais aussi de la variable dépendante (labels) | . | . Voici le visuel final, d&#39;un modèle de Deep Learning : . gv(&#39;&#39;&#39;ordering=in modèle[shape=box3d width=1 height=0.7 label=modèle] entrées-&gt;modèle-&gt;predictions; parametres-&gt;modèle; labels-&gt;pertes; predictions-&gt;pertes pertes-&gt;parametres[constraint=false label=ajustement]&#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G modèle modèle predictions predictions modèle&#45;&gt;predictions entrées entrées entrées&#45;&gt;modèle pertes pertes predictions&#45;&gt;pertes parametres parametres parametres&#45;&gt;modèle labels labels labels&#45;&gt;pertes pertes&#45;&gt;parametres ajustement En revanche, notre modèle est limité par: . Les données Leurs étendues et leurs variétés | On ne peut pas entrainer de modèle sans celles-ci | . | Le modèle à besoin de données labelisées pour s&#39;entrainer et mesurer sa performance | . Mais il faut faire attention: . Aux rétroactions (feedback loop). | Aux surapprentissage, le model peut apprendre spécifiquement le jeu de données et in fine n&#39;etre bon que sur ce jeu de données. | Aux données d&#39;entrées, qu&#39;elles ne soient pas extremement biaisais des le début par exemple. | Aux changements d&#39;environnement, entre l&#39;entrainement du modèle et son utilisation. | . Pour recapituler, un réseau de neurones est une sorte de modèle de Machine Learning et le deep learning est un réseau de neurones avec des couches suplémentaire (&gt;2). . Stochastic Gradient Descent (SGD) . Maintenant on sait à quoi servent les poids, on sait comment fonctionne le Machine Learning et on sait que les poids sont ajuster en fonction de la performance. Mais comment sont réellement ajusté les poids ? . Pour trouver les valeurs à attribuer aux poids et ce de façon automatique, nous allons utiliser la Descente de Gradient Stochastique (SGD). . La Descente de Gradient Stochastique, donne un poids à chaque unités d&#39;entrées, de façon à ce que les unités d&#39;entrées qui sont le plus probable d&#39;avoir un impact positif sur notre résultat est un plus grand poids que celles avec une faible probabilité. . La probabilité que la prediction soit positive = la somme des unités multiplié par leurs poids respective. . Nous cherchons les valeurs des poids qui nous permettront d&#39;obtenir le meilleur résultat. Il nous manque donc la manière de les améliorer. Afin de se faire nous allons réaliser quelques étapes: . Initialisation des poids de façon aléatoire | Prediction: pour chaque unités, utiliser le poids assigné pour prédire le résultat | Perte: d&#39;après ces prédictions, calculer sa performance | Gradient: comment la modification des poids impact notre performance (perte) | Ajustement des poids: en se basant sur le gradient | Repetition: retour à l&#39;étape 2. et renouvelement du processus | Stop: arret du processus d&#39;entrainement du modèle | gv(&#39;&#39;&#39; init-&gt;prediction-&gt;perte-&gt;gradient-&gt;ajustement-&gt;stop ajustement-&gt;prediction[label=repetition] &#39;&#39;&#39;) . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; G init init prediction prediction init&#45;&gt;prediction perte perte prediction&#45;&gt;perte gradient gradient perte&#45;&gt;gradient ajustement ajustement gradient&#45;&gt;ajustement ajustement&#45;&gt;prediction repetition stop stop ajustement&#45;&gt;stop Le gradient . L&#39;objectif du Gradient est d&#39;optimiser notre perte en modifiant les poids attribué aux parametres. Ce qui se passe durant 5. l&#39;ajustement. Pour ce faire le Gradient calcul la dérivée. . La dérivée calcul le changement plutot que la valeur. Elle nous indique à quelle vitesse (%) un changement a lieu entre les valeurs sous-jacente. Plus spécifiquement elle est égale à : . Le changement de valeur dans la fonction / par le changement de valeur dans les parametres . Lorsque l&#39;on sait comment la valeur va changer, nous savons comment l&#39;optimiser. Une fonction à plusieurs poids (pour chaque entrées) qui doivent etre ajuster, ce qui résulte en autant de gradient qu&#39;il y a de poids. Pour ce faire, le gradient calcul la dérivé d&#39;un poids et traite toute les autres comme des constantes, et ce pour chaque poids. . Ici réside la clef de l&#39;optimisation d&#39;un modèle de Machine Learning. . Taux d&#39;apprentissage . Le taux d&#39;apprentissage permet de décidé comment les parametres (poids) vont changer par rapport au gradient. C&#39;est à dire que l&#39;on va muliplié le taux d&#39;apprentissage par le gradient pour obtenir notre ajustement. Comme nous souhaitons minimiser notre perte, nous allons soustraire ce calcul au parametres pour les optimiser. Ceci nous permet d&#39;ajuster les parametres dans la direction du zéro. Ainsi augmentant les parametres lorsque la direction est négative et les baissant lorsque la direction est positive. Le but est d&#39;atteindre une perte la plus proche de zéro. . poids -= gradient(poids) * taux d&#39;apprentissage . Cela s&#39;appelle l&#39;étape d&#39;optimisation. Le choix du taux d&#39;apprentissage, aura un grand impact sur cette étape. Un faible taux d&#39;apprentissage, rendra le modèle lent dans son apprentissage alors qu&#39;un taux d&#39;apprentissage trop élevé peut résulté en une performance qui regresse ou divergente. . Exemple d&#39;un mod&#232;le &#224; l&#39;aide de la Descente de Gradient . Nous allons créer un gradient pour trouver la valeur minimal. . Dans cette exemple, nous mesurons la vitesse des voitures qui circulent sur le périphérique parisien chaque heure d&#39;une journée. . temps = torch.arange(0,25).float() temps . tensor([ 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.]) . vitesse = torch.randn(25)*3 + 0.85*(temps-11)**2 + 1 plt.scatter(temps, vitesse); . Voici le rendu, il semble y avoir des bouchons entre 10h et 15h, et que le traffic devient plus fluide après 20h. Il n&#39;est pas facile de déterminer a quelle vitesse roulait une voiture à une heure précise. En utilisant la Descente de Gradient, on peu estimer à l&#39;aide de la fonction quadratique: a (temps** 2)+ (b temps) +c. . Nous cherchons à distinguer entre: les entrées (le l&#39;heure (temps) à laquelle nous mesurons la vitesse des voitures) et ces parametres (la valeur qui défini quelle quadratique nous essayons). Pour ce faire nous collectons les parametres dans un unique argument afin de séparé le temps (t) et les parametres (params). . def fonction(t, params): a,b,c = params return a*(t**2) + (b*t) + c . En d&#39;autre mots, nous avons restreint le probleme, à la recherche de la meilleur fonction quadratique (a,b,c). Nous devons donc simplement trouver quels sont les meilleurs valeurs pour a, b et c. . Le procédé est le même pour les autres cas, nous cherchons la valeurs des parametres. A cette fin, nous utilison la fonction de &#39;perte&#39; qui nous retournera une valeur basé sur la différence entre la prédiction et la cible (ici la vitesse), où une faible &#39;perte&#39; nous donnera une &quot;meilleur&quot; performance. . Dans ce cas, la fonction de &#39;perte&#39; est l&#39;erreur quadratic moyenne (mean squared error) car il s&#39;agit de données continues (numérique) . def mse(predictions, cibles): return ((predictions-cibles)**2).mean() . 1. Initialisation des parametres (poids) . On initialize les poids avec des valeurs aléatoire et indiquons a PyTorch que nous souhaitons retenir leurs gradients . params = torch.randn(3).requires_grad_() . Pr&#233;dictions . Nous calculons les prédictions du modèle en utilisant la fonction précèdemment codé. . predictions = fonction(temps, params) . Maintenant visualisons, comment notre modèle performe avec des parametres aléatoire. . def show(prediction, ax=None): if ax is None: ax=plt.subplots()[1] ax.scatter(temps, vitesse) ax.scatter(temps, to_np(predictions), color=&#39;red&#39;) ax.set_ylim(-100, 250) . show(predictions) . En bleu, sont les données cibles et en rouge les données de la prédiction. On voit clairement que le parametres ne sont pas en accord avec la cible et qu&#39;il nous propose même des valeurs de vitesse négative. . Perte . Nous allons mesurer la performance de notre modèle, à l&#39;aide de la fonction mean squared error, précèdemment créer pour. . perte = mse(predictions, vitesse) perte . tensor(59678.8281, grad_fn=&lt;MeanBackward0&gt;) . Notre objectif est maintenant d&#39;améliorer ce résultat, en essayant de le diminuer au maximum. Pour cela nous allons utiliser le gradient. . Gradient . Dans cette étape nous allons calculer le gradient, soit approximativement le changement nécessaire au parametres afin qu&#39;il s&#39;améliore. . perte.backward() params.grad . tensor([128103.9688, 6573.3862, 333.9178]) . .backward() signifie &quot;Back propagation&quot;. Il s&#39;agit du processus de calcul de la dérivéee. . .grad signifie gradient. Cela nous permet d&#39;obtenir le gradient (dérivée). . Ajustement . Maintenant que l&#39;on connait le gradient. Nous devons le multiplié par un taux d&#39;apprentissage afin que la machine apprenne. Dans ce cas, on choisi arbitrairement un taux d&#39;apprentissage de 0.0001. . ta = 1e-5 params.data -= ta * params.grad.data params.grad = None . .data nous permet de ne pas calculer les gradients durant l&#39;ajustement, car on souhaite que les gradients soit calculer seulement lors de la prédiction. . Retour &#224; l&#39;&#233;tape de pr&#233;diction . Retour à l&#39;étape 2. Prédiction, ici nous allons comparer notre résultat obtenu précedemment avec celui obtenu après avoir effectué l&#39;ajustement. . predictions = fonction(temps, params) perte = mse(predictions, vitesse) perte . tensor(11477.2236, grad_fn=&lt;MeanBackward0&gt;) . On remarque la perte à baisser et c&#39;est ce que nous cherchions à faire! Notre modèle c&#39;est belle et bien amélioré. . show(predictions) . On peut aussi visualiser l&#39;amélioration de notre modèle. . Ainsi, nous pouvons créer une fonction qui permettra d&#39;effectuer toute ces étapes. . def ajustement(params, prn=True): predictions = fonction(temps, params) perte = mse(predictions, vitesse) perte.backward() params.data -= ta * params.grad.data params.grad = None if prn: print(perte.item()) return predictions . Faisons le plusieurs fois, pour voir si notre modèle s&#39;améliore. Lorsque l&#39;on défini combien d&#39;ajustement le modèle va effectuer avant de s&#39;arreter, cela s&#39;appelle une epoch. Dans le cas suivant, il y a 5 epochs. . for i in range(6): ajustement(params) . 11477.2236328125 3211.542724609375 1794.1199951171875 1551.0457763671875 1509.349853515625 1502.18701171875 . Pour r&#233;sumer . Les poids de notre modèle peuvent etre choisi de façon aléatoire ou bien venir d&#39;un modèle pré-entrainé (transfert learning). Le modèle devra alors apprendre pour trouver de meilleur poids. . A cette fin, on compare les prédictions du modèle avec les cibles (labels) à l&#39;aide de la fonction &#39;perte&#39;. Cette perte doit etre le plus proche de zéro possible. . Nos poids doivent etre amélioré, on le fait en fournissant au modèle des données. Après avoir passer les étapes du modèle, on obtient une &#39;perte&#39;, cette perte nous indique &quot;de combien le modèle à faux&quot; puis on change les poids pour obtenir un meilleur résultat. . Pour trouver comment changer les poids, on utilise le gradient (la dériviée), celui-ci est multiplié par un taux d&#39;apprentissage (ampleur de l&#39;apprentissage) qui nous donne alors la direction et l&#39;amplitude de l&#39;ajustement des poids. . Les sp&#233;cificit&#233;s . Utilisation du Deep Learning . Le Deep Learning peut etre utiliser pour remplir différentes tâches: . Vision : Detection et Classification d&#39;images | Texte : Classification (analyse du sentiment), Génération de texte et Traduction | Tableau : Classification (Travail avec beaucoup de données numérique) | &quot;Recommendation&quot; : Prédiction du prochain achat par ex. (différent de proposition | Multi-modal : Mix des precedentes catégories | Autres : Il existe de nombreuse possibilités en utilisant le Deep Learning pour completé une tâche. | . Classification et Regression . Les deux types de modèle principaux sont la classification et la regression. . Le modèle de classification prédit une catégorie (ex, un chat ou un chien). . Différent d&#39;une Regression Linéaire, le modèle de Regression prédit une ou plusieurs valeurs numérique (ex, une température) . Le mod&#232;le basic . Parfois un simple modèle basic, facile à construire, est plus performant qu&#39;un modèle de Deep Learning. De plus ce modèle basic, permet de comparer les résultats du modèle de Deep Learning avec un autre modèle. Avant de commencer, il faut construire ce modèle basic afin d&#39;essayer de trouver une solution qui soit claire et qui fournisse un résultat proche de celui espéré avec le Machine Learning. . Le modèle basic doit etre simple, il peut être constituer en quelques calculs mathématiques, en revanche le modèle basic ce veut plus performant qu&#39;un modèle qui résulte de façon aléatoire. Et bien évidemment, ce n&#39;est pas un modèle utilisant le Machine Learning. . Souvent un modèle basic, va être la représentation de notre propre réflection à la question: Comment prédire efficacement le résultat ? . Ex: Prédire le prix d&#39;un certain produit ? On calcul le prix moyen des produits de la même catégorie . La validation du mod&#232;le (metric) . Maintenant que nous savons comment entrainer un modèle, comment savoir si celui-ci est réellement performant? . Pour cela, il faut utiliser un set de validation. Ce sont des données qui ont été mis à l&#39;écart explicitement afin de comparer les prédictions de notre modèle avec la réalité. Ainsi on obtient, une mesure précise de la performance. . Mais quelle est la différence entre la perte et la metric ? . La différence réside dans le fait que la metric aide l&#39;humain à comprendre la performance du modèle alors que la perte aide la machine à apprendre de ces erreurs. . La metric est la valeur dont nous nous soucions réellement, c&#39;est la mesure qui nous indique comment le modèle performe réellement. . La perte doit être choisi de sorte à avoir une dérivée qui réagi a l&#39;ajustement des parametres. . la metric va comparer . La mesure de la performance du modèle comparant la prédiction avec un jeu de données &quot;valide&quot; s&#39;appele la &quot;metric&quot; (in fine c&#39;est la mesure en laquelle l&#39;homme juge la performance du modèle) | Le jeu de données valide (validation set) est un jeu de données mis à l&#39;écart lors de l&#39;entrainement, il permet de vérifier la performance du modèle (metric) et ne contient aucune données utilisé lors de l&#39;entrainement. | . Le transfert learning . Le transfert learning, nous permet d&#39;utiliser un modèle qui a déja été entrainé (sur d&#39;autres données proche des notres). Le modèle possèdent alors des parametres prochent de ceux que nous souhaitons obtenir pour notre prédiction. . Nous pouvons alors rapidement ré-entrainer ce modèle sur nos données pour obtenir un &quot;meilleur&quot; résultat qu&#39;un nouveau modèle. Ce n&#39;est pas nécessairement le cas (bien que souvent), mais cette aspect à la faculté d&#39;etre bien plus rapide. Cette technique permet d&#39;entrainé un modèle lorsque l&#39;on à peu de données ou bien peu de capacité de calcul (pour l&#39;entrainement du modèle). . Au lieu d&#39;utiliser des parametres choisi de façon aléatoire, les paramatres du modèle pré-entrainé sont proches de ceux que nous souhaitons obtenir. . Conclusion . Dans ce rapport, nous avons vu l&#39;histoire du Machine Learning, du Deep Learning et des Reseau de Neurones. Nous avons appris à les différencier et compris comment ils étaient relié. Nous savons comment la machine est capable d&#39;apprendre et de s&#39;améliorer. Ce rapport constitue les fondations pour aller de l&#39;avant et commencer à pousser l&#39;apprentissage plus loin. .",
            "url": "https://teilomillet.github.io/pages/2020/05/27/P8-OpenClassrooms.html",
            "relUrl": "/2020/05/27/P8-OpenClassrooms.html",
            "date": " • May 27, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://teilomillet.github.io/pages/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://teilomillet.github.io/pages/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://teilomillet.github.io/pages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://teilomillet.github.io/pages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}